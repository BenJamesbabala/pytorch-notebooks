{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MANNs for bAbI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import division, print_function\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "\n",
    "import torch\n",
    "from torch import FloatTensor, LongTensor\n",
    "from torch.nn import functional as F, Embedding, Linear, Module, Parameter\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Statement(object):\n",
    "    def __init__(self, slot, text):\n",
    "        self.slot = slot\n",
    "        self.text_strs = text\n",
    "        x.text = Variable(LongTensor([d[i] for i in self.text]))\n",
    "    \n",
    "    def torchify(self, d):\n",
    "        text = Variable(LongTensor([d[i] for i in self.text]))\n",
    "        return Statement(self.slot, text)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return 'S[{0.slot:02d}](text={0.text})'.format(self)\n",
    "\n",
    "\n",
    "class Query(object):\n",
    "    def __init__(self, slot, text, answer, refs):\n",
    "        self.slot = slot\n",
    "        self.text = text\n",
    "        self.answer = answer\n",
    "        self.refs = refs\n",
    "\n",
    "    def torchify(self, d):\n",
    "        text = Variable(LongTensor([d[i] for i in self.text]))\n",
    "        answer = Variable(LongTensor([d[i] for i in self.answer]))\n",
    "        return Query(self.slot, text, answer, list(self.refs))\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return 'Q[{0.slot:02d}](text={0.text}, answer={0.answer}, refs={0.refs})'.format(self)\n",
    "\n",
    "\n",
    "class TaskData(object):\n",
    "    def __init__(self, task, data_dir='babi-tasks_1-20_v1-2/en/'):\n",
    "        self.task = task\n",
    "        def match_one_file(p):\n",
    "            ms = [f for f in os.listdir(data_dir) if re.match(p, f)]\n",
    "            if len(ms) != 1:\n",
    "                raise ValueError('{} matched the wrong number of items: {}'.format(p, ms))\n",
    "            return os.path.join(data_dir, ms[0])\n",
    "\n",
    "        self.train_file = match_one_file(r'qa{}_.*_train.txt'.format(task))\n",
    "        with open(self.train_file) as fp:\n",
    "            self.train = self.parse(fp)\n",
    "\n",
    "        self.test_file = match_one_file(r'qa{}_.*_test.txt'.format(task))\n",
    "        with open(self.test_file) as fp:\n",
    "            self.test = self.parse(fp)\n",
    "    \n",
    "    @staticmethod\n",
    "    def parse(lines):\n",
    "        prev_slot = None\n",
    "        episodes = [[]]\n",
    "        for line in lines:\n",
    "            slot, text = line.lower().strip().split(' ', 1)\n",
    "            slot = int(slot)\n",
    "            if '\\t' in text:\n",
    "                text, answer, refs = [re.findall(r'\\w+', s) for s in text.split('\\t')]\n",
    "                refs = [int(ref) for ref in refs]\n",
    "                item = Query(slot, text, answer, refs)\n",
    "            else:\n",
    "                text = re.findall(r'\\w+', text)\n",
    "                item = Statement(slot, text)\n",
    "            if prev_slot is None or slot >  prev_slot:\n",
    "                episodes[-1].append(item)\n",
    "            else:\n",
    "                episodes.append([item])\n",
    "            prev_slot = slot\n",
    "        return episodes\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return 'TaskData(task={}, num_train={}, num_test={})'.format(self.task, len(self.train), len(self.test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TaskData(task=6, num_train=200, num_test=200)\n",
      "  train_file = babi-tasks_1-20_v1-2/en/qa6_yes-no-questions_train.txt\n",
      "  test_file  = babi-tasks_1-20_v1-2/en/qa6_yes-no-questions_test.txt\n",
      "\n",
      "S[01](text=['mary', 'moved', 'to', 'the', 'bathroom'])\n",
      "S[02](text=['sandra', 'journeyed', 'to', 'the', 'bedroom'])\n",
      "Q[03](text=['is', 'sandra', 'in', 'the', 'hallway'], answer=['no'], refs=[2])\n",
      "S[04](text=['mary', 'went', 'back', 'to', 'the', 'bedroom'])\n",
      "S[05](text=['daniel', 'went', 'back', 'to', 'the', 'hallway'])\n",
      "Q[06](text=['is', 'daniel', 'in', 'the', 'bathroom'], answer=['no'], refs=[5])\n",
      "S[07](text=['sandra', 'went', 'to', 'the', 'kitchen'])\n",
      "S[08](text=['daniel', 'went', 'back', 'to', 'the', 'bathroom'])\n",
      "Q[09](text=['is', 'daniel', 'in', 'the', 'office'], answer=['no'], refs=[8])\n",
      "S[10](text=['daniel', 'picked', 'up', 'the', 'football', 'there'])\n",
      "S[11](text=['daniel', 'went', 'to', 'the', 'bedroom'])\n",
      "Q[12](text=['is', 'daniel', 'in', 'the', 'bedroom'], answer=['yes'], refs=[11])\n",
      "S[13](text=['john', 'travelled', 'to', 'the', 'office'])\n",
      "S[14](text=['sandra', 'went', 'to', 'the', 'garden'])\n",
      "Q[15](text=['is', 'daniel', 'in', 'the', 'bedroom'], answer=['yes'], refs=[11])\n"
     ]
    }
   ],
   "source": [
    "data = TaskData(6)\n",
    "print(data)\n",
    "print('  train_file =', data.train_file)\n",
    "print('  test_file  =', data.test_file)\n",
    "print()\n",
    "for x in data.train[0]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 => mary\n",
      "1 => moved\n",
      "2 => to\n",
      "3 => the\n",
      "4 => bathroom\n",
      "5 => sandra\n",
      "6 => journeyed\n",
      "7 => bedroom\n",
      "8 => is\n",
      "9 => in\n",
      "10 => hallway\n",
      "11 => no\n",
      "12 => went\n",
      "13 => back\n",
      "14 => daniel\n",
      "15 => kitchen\n",
      "16 => office\n",
      "17 => picked\n",
      "18 => up\n",
      "19 => football\n",
      "20 => there\n",
      "21 => yes\n",
      "22 => john\n",
      "23 => travelled\n",
      "24 => garden\n",
      "25 => got\n",
      "26 => apple\n",
      "27 => put\n",
      "28 => down\n",
      "29 => grabbed\n",
      "30 => left\n",
      "31 => dropped\n",
      "32 => took\n",
      "33 => milk\n",
      "34 => discarded\n"
     ]
    }
   ],
   "source": [
    "word2id = {}\n",
    "id2word = {}\n",
    "for episode in data.train + data.test:\n",
    "    for item in episode:\n",
    "        for word in item.text + (item.answer if isinstance(item, Query) else []):\n",
    "            try:\n",
    "                i = word2id[word]\n",
    "            except KeyError:\n",
    "                word2id[word] = len(word2id)\n",
    "                id2word[word2id[word]] = word\n",
    "for i, word in sorted(id2word.items()):\n",
    "    print(i, '=>', word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LSTM(torch.nn.Module):\n",
    "    def __init__(self, n_in, n_out):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.w = Parameter(FloatTensor(n_in + n_out, 4 * n_out))\n",
    "        self.b = Parameter(FloatTensor(1, 4 * n_out))\n",
    "        self.h0 = Parameter(FloatTensor(1, n_out))\n",
    "        self.c0 = Parameter(FloatTensor(1, n_out))\n",
    "        self.reset_parameters()\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        self.w.data.normal_(0, 0.01)\n",
    "        self.b.data.zero_()\n",
    "        self.h0.data.zero_()\n",
    "        self.c0.data.zero_()\n",
    "    \n",
    "    @property\n",
    "    def initial_state(self):\n",
    "        return self.h0, self.c0\n",
    "    \n",
    "    def observable(self, s):\n",
    "        return s[0]\n",
    "    \n",
    "    def step(self, x, s=None):\n",
    "        h_prev, c_prev = s or self.initial_state\n",
    "        z = torch.cat([x, h_prev], 1)\n",
    "        a = z.mm(self.w) + self.b.expand(x.size(0), self.b.size(1))\n",
    "        i, f, o, g = torch.chunk(a, 4, dim=1)\n",
    "        i = F.sigmoid(i)\n",
    "        f = F.sigmoid(f)\n",
    "        o = F.sigmoid(o)\n",
    "        g = F.tanh(g)\n",
    "        c = f * c_prev + i * g\n",
    "        h = o * c\n",
    "        return h, c\n",
    "\n",
    "\n",
    "class RegNet(torch.nn.Module):\n",
    "    def __init__(self, n_words, embed_dim, controller_hid_dim, register_dim, n_registers):\n",
    "        super(RegNet, self).__init__()\n",
    "        self.n_words = n_words\n",
    "        self.embed_dim = embed_dim\n",
    "        self.controller_hid_dim = controller_hid_dim\n",
    "        self.register_dim = register_dim\n",
    "        self.n_registers = n_registers\n",
    "        \n",
    "        self.embedding = Embedding(n_words, embed_dim)\n",
    "        self.add = Linear(embed_dim, register_dim)\n",
    "        self.erase = Linear(embed_dim, register_dim)\n",
    "        self.controller = LSTM(embed_dim, controller_hid_dim)\n",
    "        self.attend = Linear(controller_hid_dim, n_registers)\n",
    "        self.read_key = Linear(embed_dim, register_dim)\n",
    "        self.output = Linear(register_dim, n_words)\n",
    "    \n",
    "    @property\n",
    "    def initial_state(self):\n",
    "        memory = [Variable(torch.zeros(1, self.register_dim)) for i in range(self.n_registers)]\n",
    "        return (memory, self.controller.initial_state)\n",
    "    \n",
    "    def embed(self, x):\n",
    "        return self.embedding(x).sum(0)\n",
    "    \n",
    "    def update(self, x, s=None):\n",
    "        m, r = s or self.initial_state\n",
    "        z = self.embed(x)\n",
    "        a = F.sigmoid(self.add(z))\n",
    "        e = F.sigmoid(self.erase(z))\n",
    "        r = self.controller.step(z, r)\n",
    "        g = F.softmax(self.attend(self.controller.observable(r)))\n",
    "        g = [gi.expand(a.size()) for gi in g.chunk(self.n_registers, dim=1)]\n",
    "        m = [g[i] * a + (1 - g[i]) * m[i] for i in range(self.n_registers)]\n",
    "        return m, r\n",
    "    \n",
    "    def scores(self, x, s=None):\n",
    "        m, _ = s or self.initial_state\n",
    "        z = self.embed(x)\n",
    "        k = self.read_key(z)\n",
    "        k_norm = k.norm()\n",
    "        g = [m[i].dot(k) / (m[i].norm() * k_norm) for i in range(self.n_registers)]\n",
    "        g = [g[i].unsqueeze(0).expand(m[i].size()) for i in range(self.n_registers)]\n",
    "        h = sum(g[i] * m[i] for i in range(self.n_registers))\n",
    "        return self.output(h)\n",
    "        \n",
    "    def unfold(self, xs):\n",
    "        s = self.initial_state\n",
    "        ss = []\n",
    "        ps = []\n",
    "        for x in xs:\n",
    "            if isinstance(x, Statement):\n",
    "                s = self.update(x.text, s)\n",
    "                ss.append(s)\n",
    "                ps.append(None)\n",
    "            elif isinstance(x, Query):\n",
    "                p = self.scores(x.text, s)\n",
    "                ss.append(s)\n",
    "                ps.append(p)\n",
    "            else:\n",
    "                raise TypeError('expected Statement or Query, got {}'.format(type(x)))\n",
    "        return ps, ss\n",
    "\n",
    "    def is_output(self, p, x):\n",
    "        if p is None:\n",
    "            assert isinstance(x, Statement)\n",
    "            return False\n",
    "        assert isinstance(x, Query)\n",
    "        return True\n",
    "    \n",
    "    def answer_cost(self, p, x):\n",
    "        return F.cross_entropy(p, x.answer)\n",
    "    \n",
    "    def cost(self, xs):\n",
    "        ps, _ = self.unfold(xs)\n",
    "        return sum(self.answer_cost(p, x) \n",
    "                   for p, x in zip(ps, xs) \n",
    "                       if self.is_output(p, x))\n",
    "    \n",
    "    def predict(self, xs):\n",
    "        ps, _ = self.unfold(xs)\n",
    "        return [p.data.numpy().argmax(1) \n",
    "                if self.is_output(p, x) \n",
    "                else None \n",
    "                for p, x in zip(ps, xs)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regnet = RegNet(len(word2id), 20, 15, 20, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 200\n",
      "665.530073643\n",
      "670.551208138\n",
      "667.196122169\n",
      "662.009292603\n",
      "665.453834414\n",
      "666.770536423\n",
      "663.650207877\n",
      "661.660168767\n",
      "660.056868196\n",
      "658.267350435\n",
      "656.219919324\n",
      "657.227235556\n",
      "653.741602302\n",
      "651.653306127\n",
      "648.709418893\n",
      "647.69943881\n",
      "648.588648677\n",
      "648.852978706\n",
      "645.459496737\n",
      "642.948979735\n",
      "644.346433163\n",
      "638.017903447\n",
      "637.239938259\n",
      "634.41603446\n",
      "631.183526516\n",
      "627.824265003\n",
      "626.683178067\n",
      "626.420316815\n",
      "622.437878966\n",
      "621.611734509\n",
      "617.344587088\n",
      "613.819654465\n",
      "612.776342273\n",
      "608.654447794\n",
      "607.068612933\n",
      "601.205011845\n",
      "595.352134705\n",
      "592.224013209\n",
      "588.018076777\n",
      "579.454022169\n",
      "576.218397677\n",
      "574.99883306\n",
      "570.005260229\n",
      "563.462118983\n",
      "558.412848175\n",
      "555.055948973\n",
      "544.094163418\n",
      "543.726655543\n",
      "536.603663445\n",
      "531.339917421\n",
      "527.623206377\n",
      "517.883247137\n",
      "519.240021586\n",
      "506.177681446\n",
      "498.757984102\n",
      "501.606267273\n",
      "493.918481052\n",
      "484.60589993\n",
      "474.38744086\n",
      "467.902221322\n",
      "467.738693118\n",
      "464.850767568\n",
      "452.331591189\n",
      "446.38367337\n",
      "441.085629642\n",
      "436.164363235\n",
      "425.328442663\n",
      "419.085003018\n",
      "416.797692537\n",
      "410.601911604\n",
      "403.162749726\n",
      "395.104694709\n",
      "387.457235992\n",
      "381.650844693\n",
      "383.055661291\n",
      "370.135639966\n",
      "365.761794597\n",
      "364.015924066\n",
      "352.395701334\n",
      "354.396499217\n",
      "345.477114663\n",
      "333.064958647\n",
      "329.991542488\n",
      "327.855943799\n",
      "318.642667085\n",
      "310.277268156\n",
      "307.144768439\n",
      "294.779297471\n",
      "294.466837909\n",
      "285.096309043\n",
      "277.435111312\n",
      "286.102886659\n",
      "267.177117607\n",
      "264.284093993\n",
      "258.596631583\n",
      "254.055314336\n",
      "252.626450779\n",
      "236.167080527\n",
      "236.272162568\n",
      "236.873034181\n",
      "223.910816628\n",
      "215.048874689\n",
      "211.405591561\n",
      "215.824016141\n",
      "207.486517337\n",
      "201.435407969\n",
      "190.820981708\n",
      "197.97428827\n",
      "184.983383022\n",
      "179.17340643\n",
      "176.551521198\n",
      "169.597904272\n",
      "160.428327128\n",
      "161.964767136\n",
      "152.585382661\n",
      "143.915994234\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-358-38b8bac4bdbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mregnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mnll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mnll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mregnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.005\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/thom/anaconda/lib/python2.7/site-packages/torch/autograd/variable.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_variables)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'backward should be called only on a scalar (i.e. 1-element tensor) or with gradient w.r.t. the variable'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_as_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execution_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/thom/anaconda/lib/python2.7/site-packages/torch/autograd/_functions/basic_ops.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad_output)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_train = [[x.torchify(word2id) for x in xs] for xs in data.train]\n",
    "print('Number of samples:', len(data_train))\n",
    "while True:\n",
    "    random.shuffle(data_train)\n",
    "    sum_nll = 0.0\n",
    "    for xs in data_train:\n",
    "        regnet.zero_grad()\n",
    "        nll = regnet.cost(xs)\n",
    "        nll.backward()\n",
    "        for param in regnet.parameters():\n",
    "            param.data.add_(-0.005, param.grad.data)\n",
    "        sum_nll += nll.data.numpy()[0]\n",
    "    print(sum_nll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S[01](text=['mary', 'got', 'the', 'milk', 'there']) None\n",
      "S[02](text=['john', 'moved', 'to', 'the', 'bedroom']) None\n",
      "Q[03](text=['is', 'john', 'in', 'the', 'kitchen'], answer=['no'], refs=[2])\n",
      "(['no'], [11]) (['no'], array([11]))\n",
      "S[04](text=['mary', 'discarded', 'the', 'milk']) None\n",
      "S[05](text=['john', 'went', 'to', 'the', 'garden']) None\n",
      "Q[06](text=['is', 'john', 'in', 'the', 'kitchen'], answer=['no'], refs=[5])\n",
      "(['no'], [11]) (['yes'], array([21]))\n",
      "S[07](text=['daniel', 'moved', 'to', 'the', 'bedroom']) None\n",
      "S[08](text=['daniel', 'went', 'to', 'the', 'garden']) None\n",
      "Q[09](text=['is', 'john', 'in', 'the', 'garden'], answer=['yes'], refs=[5])\n",
      "(['yes'], [21]) (['yes'], array([21]))\n",
      "S[10](text=['daniel', 'travelled', 'to', 'the', 'bathroom']) None\n",
      "S[11](text=['sandra', 'travelled', 'to', 'the', 'bedroom']) None\n",
      "Q[12](text=['is', 'daniel', 'in', 'the', 'bathroom'], answer=['yes'], refs=[10])\n",
      "(['yes'], [21]) (['no'], array([11]))\n",
      "S[13](text=['mary', 'took', 'the', 'football', 'there']) None\n",
      "S[14](text=['sandra', 'grabbed', 'the', 'milk', 'there']) None\n",
      "Q[15](text=['is', 'daniel', 'in', 'the', 'bedroom'], answer=['no'], refs=[10])\n",
      "(['no'], [11]) (['no'], array([11]))\n",
      "S[01](text=['daniel', 'went', 'back', 'to', 'the', 'kitchen']) None\n",
      "S[02](text=['mary', 'grabbed', 'the', 'apple', 'there']) None\n",
      "Q[03](text=['is', 'daniel', 'in', 'the', 'office'], answer=['no'], refs=[1])\n",
      "(['no'], [11]) (['no'], array([11]))\n",
      "S[04](text=['daniel', 'journeyed', 'to', 'the', 'office']) None\n",
      "S[05](text=['john', 'went', 'back', 'to', 'the', 'office']) None\n",
      "Q[06](text=['is', 'daniel', 'in', 'the', 'hallway'], answer=['no'], refs=[4])\n",
      "(['no'], [11]) (['no'], array([11]))\n",
      "S[07](text=['mary', 'left', 'the', 'apple']) None\n",
      "S[08](text=['daniel', 'went', 'to', 'the', 'hallway']) None\n",
      "Q[09](text=['is', 'daniel', 'in', 'the', 'hallway'], answer=['yes'], refs=[8])\n",
      "(['yes'], [21]) (['yes'], array([21]))\n",
      "S[10](text=['john', 'went', 'to', 'the', 'hallway']) None\n",
      "S[11](text=['daniel', 'picked', 'up', 'the', 'milk', 'there']) None\n",
      "Q[12](text=['is', 'john', 'in', 'the', 'kitchen'], answer=['no'], refs=[10])\n",
      "(['no'], [11]) (['no'], array([11]))\n",
      "S[13](text=['john', 'grabbed', 'the', 'football', 'there']) None\n",
      "S[14](text=['mary', 'got', 'the', 'apple', 'there']) None\n",
      "Q[15](text=['is', 'daniel', 'in', 'the', 'hallway'], answer=['yes'], refs=[8])\n",
      "(['yes'], [21]) (['yes'], array([21]))\n"
     ]
    }
   ],
   "source": [
    "for i, xs in enumerate(data.test):\n",
    "    if i >= 2:\n",
    "        break\n",
    "    xs_vars = [x.torchify(word2id) for x in xs]\n",
    "    ps = regnet.predict(xs_vars)\n",
    "    assert(len(ps) == len(xs))\n",
    "    for x, p in zip(xs, ps):\n",
    "        if p is None:\n",
    "            print(x, None)\n",
    "        else:\n",
    "            print(x)\n",
    "            print((x.answer, [word2id[w] for w in x.answer]),\n",
    "                  ([id2word[j] for j in p.tolist()], p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_error(ds):\n",
    "    errors = 0.0\n",
    "    total = 0.0\n",
    "    for xs in ds:\n",
    "        xs_vars = [x.torchify(word2id) for x in xs]\n",
    "        ps = regnet.predict(xs_vars)\n",
    "        assert(len(ps) == len(xs))\n",
    "        for x, p in zip(xs, ps):\n",
    "            if p is not None:\n",
    "                if x.answer != [id2word[i] for i in p.tolist()]:\n",
    "                    errors += 1\n",
    "                total += 1\n",
    "    print(errors, total)\n",
    "    return errors, total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281.0 1000.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(281.0, 1000.0)"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_error(data.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
